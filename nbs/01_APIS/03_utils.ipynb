{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions\n",
    "\n",
    "> More on this soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import numba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def divide_on_feature(X, feature_i, threshold):\n",
    "    \"\"\" Divide dataset based on if sample value on feature index is larger than\n",
    "        the given threshold \"\"\"\n",
    "    split_func = None\n",
    "    if isinstance(threshold, int) or isinstance(threshold, float):\n",
    "        split_func = lambda sample: sample[feature_i] >= threshold\n",
    "    elif isinstance(threshold,list):\n",
    "        split_func = lambda sample: sample[feature_i].isin(threshold)\n",
    "    else:\n",
    "        split_func = lambda sample: sample[feature_i] == threshold\n",
    "\n",
    "    # X_1 = np.array([sample for sample in X if split_func(sample)])\n",
    "    # X_2 = np.array([sample for sample in X if not split_func(sample)])\n",
    "    # return np.array([X_1, X_2])\n",
    "\n",
    "    mask = split_func(X)\n",
    "    X_1 = X[mask]\n",
    "    X_2 = X[~mask]\n",
    "    return X_1,X_2\n",
    "    \n",
    "def get_sorted_cats(x,ascending=True):\n",
    "    u, count = np.unique(x, return_counts=True)\n",
    "    if ascending:\n",
    "        count_sort_ind = np.argsort(count)\n",
    "    else:\n",
    "        count_sort_ind = np.argsort(-count)\n",
    "    return u[count_sort_ind]\n",
    "\n",
    "\n",
    "def calculate_entropy(y):\n",
    "    \"\"\" Calculate the entropy of label array y \"\"\"\n",
    "    log2 = lambda x: math.log(x) / math.log(2)\n",
    "    unique_labels = np.unique(y)\n",
    "    entropy = 0\n",
    "    for label in unique_labels:\n",
    "        count = len(y[y == label])\n",
    "        p = count / len(y)\n",
    "        entropy += -p * log2(p)\n",
    "    return entropy\n",
    "\n",
    "\n",
    "def mean_squared_error(y_true, y_pred):\n",
    "    \"\"\" Returns the mean squared error between y_true and y_pred \"\"\"\n",
    "    mse = np.mean(np.power(y_true - y_pred, 2))\n",
    "    return mse\n",
    "\n",
    "\n",
    "def calculate_variance(X):\n",
    "    \"\"\" Return the variance of the features in dataset X \"\"\"\n",
    "    mean = np.ones(np.shape(X)) * X.mean(0)\n",
    "    n_samples = np.shape(X)[0]\n",
    "    variance = (1 / n_samples) * np.diag((X - mean).T.dot(X - mean))\n",
    "    \n",
    "    return variance\n",
    "\n",
    "\n",
    "def calculate_std_dev(X):\n",
    "    \"\"\" Calculate the standard deviations of the features in dataset X \"\"\"\n",
    "    std_dev = np.sqrt(calculate_variance(X))\n",
    "    return std_dev\n",
    "\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\" Calculates the l2 distance between two vectors \"\"\"\n",
    "    distance = 0\n",
    "    # Squared distance between each coordinate\n",
    "    for i in range(len(x1)):\n",
    "        distance += pow((x1[i] - x2[i]), 2)\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\" Compare y_true to y_pred and return the accuracy \"\"\"\n",
    "    accuracy = np.sum(y_true == y_pred, axis=0) / len(y_true)\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def calculate_covariance_matrix(X, Y=None):\n",
    "    \"\"\" Calculate the covariance matrix for the dataset X \"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    n_samples = np.shape(X)[0]\n",
    "    covariance_matrix = (1 / (n_samples-1)) * (X - X.mean(axis=0)).T.dot(Y - Y.mean(axis=0))\n",
    "\n",
    "    return np.array(covariance_matrix, dtype=float)\n",
    " \n",
    "\n",
    "def calculate_correlation_matrix(X, Y=None):\n",
    "    \"\"\" Calculate the correlation matrix for the dataset X \"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    n_samples = np.shape(X)[0]\n",
    "    covariance = (1 / n_samples) * (X - X.mean(0)).T.dot(Y - Y.mean(0))\n",
    "    std_dev_X = np.expand_dims(calculate_std_dev(X), 1)\n",
    "    std_dev_y = np.expand_dims(calculate_std_dev(Y), 1)\n",
    "    correlation_matrix = np.divide(covariance, std_dev_X.dot(std_dev_y.T))\n",
    "\n",
    "    return np.array(correlation_matrix, dtype=float)\n",
    "\n",
    "def linear_kernel(**kwargs):\n",
    "    def f(x1, x2):\n",
    "        return np.inner(x1, x2)\n",
    "    return f\n",
    "\n",
    "\n",
    "def polynomial_kernel(power, coef, **kwargs):\n",
    "    def f(x1, x2):\n",
    "        return (np.inner(x1, x2) + coef)**power\n",
    "    return f\n",
    "\n",
    "\n",
    "def rbf_kernel(gamma, **kwargs):\n",
    "    def f(x1, x2):\n",
    "        distance = np.linalg.norm(x1 - x2) ** 2\n",
    "        return np.exp(-gamma * distance)\n",
    "    return f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
