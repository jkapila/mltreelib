{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils.functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions\n",
    "\n",
    "> More on this soon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "import numba\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def calculate_entropy(y):\n",
    "    \"\"\"\n",
    "    Entropy of a label sequence\n",
    "    \"\"\"\n",
    "    hist = np.bincount(y)\n",
    "    ps = hist / np.sum(hist)\n",
    "    return -np.sum([p * np.log2(p) for p in ps if p > 0])\n",
    "\n",
    "\n",
    "def calculate_gini(y):\n",
    "    \"\"\"\n",
    "    Gini impurity (local entropy) of a label sequence\n",
    "    \"\"\"\n",
    "    hist = np.bincount(y)\n",
    "    N = np.sum(hist)\n",
    "    return 1 - sum([(i / N) ** 2 for i in hist])\n",
    "\n",
    "def divide_on_feature(X, feature_i, threshold):\n",
    "    \"\"\" \n",
    "    Divide dataset based on if sample value on feature index is larger than the given threshold \n",
    "    \"\"\"\n",
    "    split_func = None\n",
    "    if isinstance(threshold, int) or isinstance(threshold, float):\n",
    "        split_func = lambda sample: sample[feature_i] >= threshold\n",
    "    elif isinstance(threshold,list):\n",
    "        split_func = lambda sample: sample[feature_i].isin(threshold)\n",
    "    else:\n",
    "        split_func = lambda sample: sample[feature_i] == threshold\n",
    "\n",
    "    # X_1 = np.array([sample for sample in X if split_func(sample)])\n",
    "    # X_2 = np.array([sample for sample in X if not split_func(sample)])\n",
    "    # return np.array([X_1, X_2])\n",
    "\n",
    "    mask = split_func(X)\n",
    "    X_1 = X[mask]\n",
    "    X_2 = X[~mask]\n",
    "    return X_1,X_2\n",
    "    \n",
    "def get_sorted_cats(x,ascending=True):    \n",
    "    \"\"\"\n",
    "     Get sorted list of categorical levels in defined order\n",
    "    \"\"\"\n",
    "    u, count = np.unique(x, return_counts=True)\n",
    "    if ascending:\n",
    "        count_sort_ind = np.argsort(count)\n",
    "    else:\n",
    "        count_sort_ind = np.argsort(-count)\n",
    "    return u[count_sort_ind]\n",
    "\n",
    "\n",
    "def calculate_mse(y):\n",
    "    \"\"\" Returns the mean squared error between y_true and y_mean \"\"\"\n",
    "    mse = np.mean(np.power(y_true - np.mean(y), 2))\n",
    "    return mse\n",
    "\n",
    "\n",
    "def calculate_mae(y):\n",
    "    \"\"\" Returns the mean absolute error between y_true and y_mean \"\"\"\n",
    "    mae = np.mean(np.abs(y_true - np.mean(y)))\n",
    "    return mae\n",
    "\n",
    "def calculate_rss(y):\n",
    "    \"\"\" Returns the sum of residual squared error between y_true and y_mean \"\"\"\n",
    "    rss = np.sum((y - np.mean(y)) ** 2)\n",
    "    return rss\n",
    "\n",
    "\n",
    "def calculate_variance(X):\n",
    "    \"\"\" Return the variance of the features in dataset X \"\"\"\n",
    "    mean = np.ones(np.shape(X)) * X.mean(0)\n",
    "    n_samples = np.shape(X)[0]\n",
    "    variance = (1 / n_samples) * np.diag((X - mean).T.dot(X - mean))\n",
    "    \n",
    "    return variance\n",
    "\n",
    "\n",
    "def calculate_std_dev(X):\n",
    "    \"\"\" Calculate the standard deviations of the features in dataset X \"\"\"\n",
    "    std_dev = np.sqrt(calculate_variance(X))\n",
    "    return std_dev\n",
    "\n",
    "\n",
    "def euclidean_distance(x1, x2):\n",
    "    \"\"\" Calculates the l2 distance between two vectors \"\"\"\n",
    "    distance = 0\n",
    "    # Squared distance between each coordinate\n",
    "    for i in range(len(x1)):\n",
    "        distance += np.power((x1[i] - x2[i]), 2)\n",
    "    return np.sqrt(distance)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_covariance_matrix(X, Y=None):\n",
    "    \"\"\" Calculate the covariance matrix for the dataset X \"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    n_samples = np.shape(X)[0]\n",
    "    covariance_matrix = (1 / (n_samples-1)) * (X - X.mean(axis=0)).T.dot(Y - Y.mean(axis=0))\n",
    "\n",
    "    return np.array(covariance_matrix, dtype=float)\n",
    " \n",
    "\n",
    "def calculate_correlation_matrix(X, Y=None):\n",
    "    \"\"\" Calculate the correlation matrix for the dataset X \"\"\"\n",
    "    if Y is None:\n",
    "        Y = X\n",
    "    n_samples = np.shape(X)[0]\n",
    "    covariance = (1 / n_samples) * (X - X.mean(0)).T.dot(Y - Y.mean(0))\n",
    "    std_dev_X = np.expand_dims(calculate_std_dev(X), 1)\n",
    "    std_dev_y = np.expand_dims(calculate_std_dev(Y), 1)\n",
    "    correlation_matrix = np.divide(covariance, std_dev_X.dot(std_dev_y.T))\n",
    "\n",
    "    return np.array(correlation_matrix, dtype=float)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
