{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "> A simple adaptor class to make the data in required format that can be easily consumed and processd by the models.\n",
    "> The key aspect here is to make adaptable and fast prcessable dataset, reduce the data size, make splits and add any processing if required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.utils import *\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc, copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Dataset:\n",
    "    \"\"\"\n",
    "    Dataset Adaptor Class\n",
    "\n",
    "    This class is meant to make dataset possible which would be consumed by models further\n",
    "    \"\"\"\n",
    "    def __init__(self, df:pd.DataFrame,      # Dataframe that needs to be converted \n",
    "                reduce_datatype:bool = True, # Shall we try to reduce datatype to make is smaller\n",
    "                encode_category:str = None,  # Do encoding of categories default to None as no encoding\n",
    "                add_intercept:bool = False,  # Add a constant value intercept to data. This might be needed for Model based Trees.\n",
    "                na_treatment:str = 'allow',  # How to work with nas. Default: 'allow'\n",
    "                copy_data:bool = False,      # Keep a self copy of original data\n",
    "                digits:int = None,           # To round float to certain digits or not, Default: None means no rounding\n",
    "                n_category:Union[int, float, None] = None  # How many different level shoud be treated as category. If a value less than one the number of levels is defined aas % oft total rows\n",
    "                ) -> None:\n",
    "        self.df, self.reduce_datatype = df, reduce_datatype\n",
    "        self.encode_category, self.add_intercept = encode_category, add_intercept\n",
    "        self.na_treatment, self.copy,self.digits = na_treatment, copy_data, digits\n",
    "        self.n_category = n_category\n",
    "        self.split_ratio = None\n",
    "        self.features_ = self.df.columns.tolist()\n",
    "        self._shape = self.df.shape\n",
    "        self._dtypes = self.df.dtypes\n",
    "        self._category_lbl_dict = {}\n",
    "        self._dataranges = {}\n",
    "        \n",
    "        self._process_data()      \n",
    "\n",
    "    def _reduce_size(self):\n",
    "        df = pd.DataFrame()\n",
    "        for col,dtype in self._dtypes.items():\n",
    "            if dtype != object:\n",
    "                max_,min_,hasna_ = self.df[col].max(),self.df[col].min(),np.isfinite(self.df[col]).all()\n",
    "                isint_ = dtype == int\n",
    "                if not hasna_:\n",
    "                    asint = self.df[col].fillna(0).astype(np.int64)\n",
    "                    result = (self.df[col] - asint).sum()\n",
    "                    if -0.01 < result < 0.01:\n",
    "                        isint_ = True\n",
    "\n",
    "                # Make Integer/unsigned Integer datatypes\n",
    "                if isint_:\n",
    "                    if min_ >= 0:\n",
    "                        df[col] = pd.to_numeric(self.df[col].fillna(min_-1), downcast=\"unsigned\",errors='coerce')\n",
    "                    else:\n",
    "                        df[col] = pd.to_numeric(self.df[col].fillna(min_-1), downcast=\"integer\",errors='coerce')\n",
    "                        \n",
    "                    self._dataranges[col] = {'hasna':hasna_,'min':min_-1,'max':max_,'inferredtype':df[col].dtype}\n",
    "\n",
    "                # Make float datatypes 32 bit\n",
    "                else: #todo make this more advanced with rounding and more : evaluate the below an\n",
    "                    if self.digits is None:\n",
    "                        df[col] = pd.to_numeric(self.df[col], downcast=\"float\",errors='coerce')\n",
    "                    else:\n",
    "                        df[col] = pd.to_numeric(np.round(self.df[col],self.digits), downcast=\"float\",errors='coerce')\n",
    "                        max_,min_,hasna_ = df[col].max(),df[col].min(),np.isfinite(df[col]).all()\n",
    "                    self._dataranges[col] = {'hasna':hasna_,'min':min_,'max':max_,'inferredtype':df[col].dtype}\n",
    "            else:\n",
    "                #todo : add logic of makig a bing object to small category based on defintion\n",
    "                df[col] =self.df[col]\n",
    "                self._dataranges[col] = {'hasna':hasna_,'min':None,'max':None,'inferredtype':df[col].dtype}\n",
    "        \n",
    "        try: \n",
    "            self.data = np.array([tuple(x) for x in df.values], dtype=[(k,v['inferredtype']) for k,v in self._dataranges.items()])\n",
    "        except:\n",
    "            print('Their was an error in above')\n",
    "            self.data = df.copy(deep=True)\n",
    "\n",
    "    def _process_data(self):\n",
    "        self._reduce_size()\n",
    "        if not self.copy:\n",
    "            self.df = None\n",
    "            gc.collect()\n",
    "\n",
    "    def dtypes(self,actual=False):\n",
    "        if actual:\n",
    "            return pd.DataFrame.from_dict(self._dtypes,orient='index').rename(columns={0:'data_type'})\n",
    "        else:\n",
    "            dt = {k:v['inferredtype'] for k,v in self._dataranges.items()}\n",
    "\n",
    "    @property\n",
    "    def shape(self): return self._shape\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        s = f\"Dataset(df=Shape({self.shape}\"\n",
    "        for k,v in self.__dict__.items() :\n",
    "            if (k not in ('df','features_','data')) and (not k.startswith('_')) : s += f\", {k}={v}\"\n",
    "        s += ')'\n",
    "        return s\n",
    "    \n",
    "    __repr__ = __str__\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to work on data\n",
    "\n",
    "\n",
    "Creating random sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>numericfull</th>\n",
       "      <th>unitint</th>\n",
       "      <th>floatfull</th>\n",
       "      <th>floatsmall</th>\n",
       "      <th>categoryobj</th>\n",
       "      <th>stringobj</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>304</td>\n",
       "      <td>1</td>\n",
       "      <td>0.651859</td>\n",
       "      <td>11.42</td>\n",
       "      <td>a</td>\n",
       "      <td>f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>212</td>\n",
       "      <td>1</td>\n",
       "      <td>0.906869</td>\n",
       "      <td>23.28</td>\n",
       "      <td>d</td>\n",
       "      <td>v</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>295</td>\n",
       "      <td>23</td>\n",
       "      <td>0.933262</td>\n",
       "      <td>21.79</td>\n",
       "      <td>d</td>\n",
       "      <td>t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>19</td>\n",
       "      <td>0.919103</td>\n",
       "      <td>9.24</td>\n",
       "      <td>d</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>205</td>\n",
       "      <td>9</td>\n",
       "      <td>0.262066</td>\n",
       "      <td>16.69</td>\n",
       "      <td>a</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   numericfull  unitint  floatfull  floatsmall categoryobj stringobj\n",
       "0          304        1   0.651859       11.42           a         f\n",
       "1          212        1   0.906869       23.28           d         v\n",
       "2          295       23   0.933262       21.79           d         t\n",
       "3           54       19   0.919103        9.24           d         s\n",
       "4          205        9   0.262066       16.69           a         l"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_size = 1000000\n",
    "rnd = np.random.RandomState(1234)\n",
    "dummy_data = pd.DataFrame({'numericfull':rnd.randint(1,500,size=n_size),\n",
    "                            'unitint':rnd.randint(1,25,size=n_size),\n",
    "                            'floatfull':rnd.random_sample(size=n_size),\n",
    "                            'floatsmall':np.round(rnd.random_sample(size=n_size)+rnd.randint(1,25,size=n_size),2),\n",
    "                            'categoryobj':rnd.choice(['a','b','c','d'],size=n_size),\n",
    "                            'stringobj':rnd.choice([\"{:c}\".format(k) for k in range(97, 123)],size=n_size)})\n",
    "dummy_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass it to `Dataset`  and let it do its magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset(df=Shape((1000000, 6), reduce_datatype=True, encode_category=None, add_intercept=False, na_treatment=allow, copy=False, digits=None, n_category=None, split_ratio=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset(df=dummy_data)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To acess raw processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(304,  1, 0.65185905, 11.42, 'a', 'f'),\n",
       "       (212,  1, 0.90686905, 23.28, 'd', 'v'),\n",
       "       (295, 23, 0.9332624 , 21.79, 'd', 't'),\n",
       "       ( 54, 19, 0.9191031 ,  9.24, 'd', 's'),\n",
       "       (205,  9, 0.2620663 , 16.69, 'a', 'l')],\n",
       "      dtype=[('numericfull', '<u2'), ('unitint', 'u1'), ('floatfull', '<f4'), ('floatsmall', '<f4'), ('categoryobj', 'O'), ('stringobj', 'O')])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** This is a [Structured arrays](https://numpy.org/doc/stable/user/basics.rec.html) and not a simmple numpy array or pandas data frame.\n",
    "\n",
    "Size reduction is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Data Frame        :  148.0 MB\n",
      "Dataset Structured Array :  27.0 MB\n"
     ]
    }
   ],
   "source": [
    "print('Pandas Data Frame        : ',np.round(dummy_data.memory_usage(deep=True).sum()*1e-6,2),'MB')\n",
    "print('Dataset Structured Array : ',np.round(dataset.data.nbytes*1e-6/ 1024 * 1024,2),'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000000 entries, 0 to 999999\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count    Dtype  \n",
      "---  ------       --------------    -----  \n",
      " 0   numericfull  1000000 non-null  int64  \n",
      " 1   unitint      1000000 non-null  int64  \n",
      " 2   floatfull    1000000 non-null  float64\n",
      " 3   floatsmall   1000000 non-null  float64\n",
      " 4   categoryobj  1000000 non-null  object \n",
      " 5   stringobj    1000000 non-null  object \n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 141.1 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(dummy_data.info(memory_usage='deep'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further reduction in data size\n",
    "\n",
    "We can even further reduce data by using following parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas Data Frame        :  148.0 MB\n",
      "Dataset Structured Array :  27.0 MB\n"
     ]
    }
   ],
   "source": [
    "dataset = Dataset(df=dummy_data, digits=2)\n",
    "print('Pandas Data Frame        : ',np.round(dummy_data.memory_usage(deep=True).sum()*1e-6,2),'MB')\n",
    "print('Dataset Structured Array : ',np.round(dataset.data.nbytes*1e-6/ 1024 * 1024,2),'MB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(304,  1, 0.65, 11.42, 'a', 'f'), (212,  1, 0.91, 23.28, 'd', 'v'),\n",
       "       (295, 23, 0.93, 21.79, 'd', 't'), ( 54, 19, 0.92,  9.24, 'd', 's'),\n",
       "       (205,  9, 0.26, 16.69, 'a', 'l')],\n",
       "      dtype=[('numericfull', '<u2'), ('unitint', 'u1'), ('floatfull', '<f4'), ('floatsmall', '<f4'), ('categoryobj', 'O'), ('stringobj', 'O')])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.features_\n",
    "# dummy_data.to_dict?\n",
    "# data._dtypes = data.df.dtypes.to_dict()\n",
    "# data._dtypes\n",
    "# dummy_data.rename?\n",
    "# {k:v==object for k,v in data._dtypes.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mltreedev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aa459615d486078b116a72c354f12cd7cc759d106bcc5e574dd99ad999f0993f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
