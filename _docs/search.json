[
  {
    "objectID": "00_Examples/core.html",
    "href": "00_Examples/core.html",
    "title": "core",
    "section": "",
    "text": "source\n\nfoo\n\n foo ()"
  },
  {
    "objectID": "00_Examples/00_dataset.html",
    "href": "00_Examples/00_dataset.html",
    "title": "How to work with Datasets",
    "section": "",
    "text": "n_size = 1000000\nrnd = np.random.RandomState(1234)\ndummy_data = pd.DataFrame({'numericfull':rnd.randint(1,500,size=n_size),\n                            'unitint':rnd.randint(1,25,size=n_size),\n                            'floatfull':rnd.random_sample(size=n_size),\n                            'floatsmall':np.round(rnd.random_sample(size=n_size)+rnd.randint(1,25,size=n_size),2),\n                            'categoryobj':rnd.choice(['a','b','c','d'],size=n_size),\n                            'stringobj':rnd.choice([\"{:c}\".format(k) for k in range(97, 123)],size=n_size)})\ndummy_data.head()\n\n\n\n\n\n  \n    \n      \n      numericfull\n      unitint\n      floatfull\n      floatsmall\n      categoryobj\n      stringobj\n    \n  \n  \n    \n      0\n      304\n      1\n      0.651859\n      11.42\n      a\n      f\n    \n    \n      1\n      212\n      1\n      0.906869\n      23.28\n      d\n      v\n    \n    \n      2\n      295\n      23\n      0.933262\n      21.79\n      d\n      t\n    \n    \n      3\n      54\n      19\n      0.919103\n      9.24\n      d\n      s\n    \n    \n      4\n      205\n      9\n      0.262066\n      16.69\n      a\n      l\n    \n  \n\n\n\n\nPass it to Dataset and let it do its magic\n\ndataset = Dataset(df=dummy_data)\ndataset\n\nDataset(df=Shape((1000000, 6), reduce_datatype=True, encode_category=None, add_intercept=False, na_treatment=allow, copy=False, digits=None, n_category=None, split_ratio=None)\n\n\nTo acess raw processed data\n\ndataset.data[:5]\n\narray([(304,  1, 0.65185905, 11.42, 'a', 'f'),\n       (212,  1, 0.90686905, 23.28, 'd', 'v'),\n       (295, 23, 0.9332624 , 21.79, 'd', 't'),\n       ( 54, 19, 0.9191031 ,  9.24, 'd', 's'),\n       (205,  9, 0.2620663 , 16.69, 'a', 'l')],\n      dtype=[('numericfull', '<u2'), ('unitint', 'u1'), ('floatfull', '<f4'), ('floatsmall', '<f4'), ('categoryobj', 'O'), ('stringobj', 'O')])\n\n\nNote: This is a Structured arrays and not a simmple numpy array or pandas data frame.\nSize reduction is as follows:\n\nprint('Pandas Data Frame        : ',np.round(dummy_data.memory_usage(deep=True).sum()*1e-6,2),'MB')\nprint('Dataset Structured Array : ',np.round(dataset.data.nbytes*1e-6/ 1024 * 1024,2),'MB')\n\nPandas Data Frame        :  148.0 MB\nDataset Structured Array :  27.0 MB\n\n\n\nprint(dummy_data.info(memory_usage='deep'))\n\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 1000000 entries, 0 to 999999\nData columns (total 6 columns):\n #   Column       Non-Null Count    Dtype  \n---  ------       --------------    -----  \n 0   numericfull  1000000 non-null  int64  \n 1   unitint      1000000 non-null  int64  \n 2   floatfull    1000000 non-null  float64\n 3   floatsmall   1000000 non-null  float64\n 4   categoryobj  1000000 non-null  object \n 5   stringobj    1000000 non-null  object \ndtypes: float64(2), int64(2), object(2)\nmemory usage: 141.1 MB\nNone\n\n\n\nFurther reduction in data size\nWe can even further reduce data by using following parameters:\n\ndataset = Dataset(df=dummy_data, digits=2)\nprint('Pandas Data Frame        : ',np.round(dummy_data.memory_usage(deep=True).sum()*1e-6,2),'MB')\nprint('Dataset Structured Array : ',np.round(dataset.data.nbytes*1e-6/ 1024 * 1024,2),'MB')\n\nPandas Data Frame        :  148.0 MB\nDataset Structured Array :  27.0 MB\n\n\n\ndataset.data[:5]\n\narray([(304,  1, 0.65, 11.42, 'a', 'f'), (212,  1, 0.91, 23.28, 'd', 'v'),\n       (295, 23, 0.93, 21.79, 'd', 't'), ( 54, 19, 0.92,  9.24, 'd', 's'),\n       (205,  9, 0.26, 16.69, 'a', 'l')],\n      dtype=[('numericfull', '<u2'), ('unitint', 'u1'), ('floatfull', '<f4'), ('floatsmall', '<f4'), ('categoryobj', 'O'), ('stringobj', 'O')])"
  },
  {
    "objectID": "01_APIS/utils.html",
    "href": "01_APIS/utils.html",
    "title": "Utility functions",
    "section": "",
    "text": "source\n\nrbf_kernel\n\n rbf_kernel (gamma, **kwargs)\n\n\nsource\n\n\npolynomial_kernel\n\n polynomial_kernel (power, coef, **kwargs)\n\n\nsource\n\n\nlinear_kernel\n\n linear_kernel (**kwargs)\n\n\nsource\n\n\ncalculate_correlation_matrix\n\n calculate_correlation_matrix (X, Y=None)\n\nCalculate the correlation matrix for the dataset X\n\nsource\n\n\ncalculate_covariance_matrix\n\n calculate_covariance_matrix (X, Y=None)\n\nCalculate the covariance matrix for the dataset X\n\nsource\n\n\naccuracy_score\n\n accuracy_score (y_true, y_pred)\n\nCompare y_true to y_pred and return the accuracy\n\nsource\n\n\neuclidean_distance\n\n euclidean_distance (x1, x2)\n\nCalculates the l2 distance between two vectors\n\nsource\n\n\ncalculate_std_dev\n\n calculate_std_dev (X)\n\nCalculate the standard deviations of the features in dataset X\n\nsource\n\n\ncalculate_variance\n\n calculate_variance (X)\n\nReturn the variance of the features in dataset X\n\nsource\n\n\nmean_squared_error\n\n mean_squared_error (y_true, y_pred)\n\nReturns the mean squared error between y_true and y_pred\n\nsource\n\n\ncalculate_entropy\n\n calculate_entropy (y)\n\nCalculate the entropy of label array y\n\nsource\n\n\nget_sorted_cats\n\n get_sorted_cats (x, ascending=True)\n\n\nsource\n\n\ndivide_on_feature\n\n divide_on_feature (X, feature_i, threshold)\n\nDivide dataset based on if sample value on feature index is larger than the given threshold"
  },
  {
    "objectID": "01_APIS/basetree.html",
    "href": "01_APIS/basetree.html",
    "title": "BaseTree",
    "section": "",
    "text": "source\n\nBaseDecisionTree\n\n BaseDecisionTree (min_samples_split:int=20, min_impurity:float=1e-07,\n                   min_sample_leaf:int=10, max_depth:int=inf,\n                   loss:str=None, verbose:Union[bool,int]=False,\n                   digits:Union[int,NoneType]=2)\n\nSuper class of RegressionTree and ClassificationTree.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmin_samples_split\nint\n20\nThe minimum number of samples needed to make a split when building a tree.\n\n\nmin_impurity\nfloat\n1e-07\nThe minimum impurity required to split the tree further.\n\n\nmin_sample_leaf\nint\n10\nMinimum sample required to have a leaf node\n\n\nmax_depth\nint\ninf\nThe maximum depth of a tree.\n\n\nloss\nstr\nNone\nString of loss or funciton which defines the loss. This amounts to Loss function that is used for Gradient Boosting models to calculate impurity.\n\n\nverbose\ntyping.Union[bool, int]\nFalse\nVerbosity for tree builidng\n\n\ndigits\ntyping.Union[int, NoneType]\n2\nTo round the values before doing a split\n\n\n\n\nsource\n\n\nDecisionNode\n\n DecisionNode (feature_i:Union[str,int]=None, threshold:float=None,\n               value=None, true_branch=None, false_branch=None,\n               depth:int=None)\n\nClass that represents a decision node or leaf in the decision tree\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nfeature_i\ntyping.Union[str, int]\nNone\nFeature index which we want to use as the threshold measure.\n\n\nthreshold\nfloat\nNone\nThe value that we will compare feature values at feature_i against to determine the prediction.\n\n\nvalue\nNoneType\nNone\nThe class prediction if classification tree, or float value if regression tree.\n\n\ntrue_branch\nNoneType\nNone\nNext decision node for samples where features value met the threshold.\n\n\nfalse_branch\nNoneType\nNone\nNext decision node for samples where features value did not meet the threshold.\n\n\ndepth\nint\nNone\ndepth of current node"
  },
  {
    "objectID": "01_APIS/tree.html",
    "href": "01_APIS/tree.html",
    "title": "Tree Implementations",
    "section": "",
    "text": "source\n\nTree\n\n Tree ()\n\nTree class enable building all simpe single tree models\n\nsource\n\n\nCARTRegressionTree\n\n CARTRegressionTree (min_samples_split:int=20, min_impurity:float=1e-07,\n                     min_sample_leaf:int=10, max_depth:int=inf,\n                     loss:str=None, verbose:Union[bool,int]=False,\n                     digits:Union[int,NoneType]=2)\n\nSuper class of RegressionTree and ClassificationTree.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nmin_samples_split\nint\n20\nThe minimum number of samples needed to make a split when building a tree.\n\n\nmin_impurity\nfloat\n1e-07\nThe minimum impurity required to split the tree further.\n\n\nmin_sample_leaf\nint\n10\nMinimum sample required to have a leaf node\n\n\nmax_depth\nint\ninf\nThe maximum depth of a tree.\n\n\nloss\nstr\nNone\nString of loss or funciton which defines the loss. This amounts to Loss function that is used for Gradient Boosting models to calculate impurity.\n\n\nverbose\ntyping.Union[bool, int]\nFalse\nVerbosity for tree builidng\n\n\ndigits\ntyping.Union[int, NoneType]\n2\nTo round the values before doing a split"
  },
  {
    "objectID": "01_APIS/data.html",
    "href": "01_APIS/data.html",
    "title": "Dataset",
    "section": "",
    "text": "source\n\nDataset\n\n Dataset (df:pandas.core.frame.DataFrame, reduce_datatype:bool=True,\n          encode_category:str=None, add_intercept:bool=False,\n          na_treatment:str='allow', copy_data:bool=False, digits:int=None,\n          n_category:Union[int,float,NoneType]=None)\n\nDataset Adaptor Class\nThis class is meant to make dataset possible which would be consumed by models further\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndf\nDataFrame\n\nDataframe that needs to be converted\n\n\nreduce_datatype\nbool\nTrue\nShall we try to reduce datatype to make is smaller\n\n\nencode_category\nstr\nNone\nDo encoding of categories default to None as no encoding\n\n\nadd_intercept\nbool\nFalse\nAdd a constant value intercept to data. This might be needed for Model based Trees.\n\n\nna_treatment\nstr\nallow\nHow to work with nas. Default: ‘allow’\n\n\ncopy_data\nbool\nFalse\nKeep a self copy of original data\n\n\ndigits\nint\nNone\nTo round float to certain digits or not, Default: None means no rounding\n\n\nn_category\ntyping.Union[int, float, NoneType]\nNone\nHow many different level shoud be treated as category. If a value less than one the number of levels is defined aas % oft total rows\n\n\nReturns\nNone\n\n\n\n\n\n\n\nHow to work on data\nPlease refer Examples"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "mltree",
    "section": "",
    "text": "This package evovled from the attempt to make right kind of Decision Tress which was ideated by many people like Hastie, Tibshirani, Friedman, Quilan, Loh, Chaudhari."
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "mltree",
    "section": "Install",
    "text": "Install\npip install mltreelib"
  },
  {
    "objectID": "index.html#how-to-use",
    "href": "index.html#how-to-use",
    "title": "mltree",
    "section": "How to use",
    "text": "How to use\nCreate a sample data\n\nimport numpy as np\nimport pandas as pd\nfrom mltreelib.data import Dataset\nfrom mltreelib.tree import Tree\n\n\nn_size = 1000\nrnd = np.random.RandomState(1234)\ndummy_data = pd.DataFrame({'numericfull':rnd.randint(1,500,size=n_size),\n                            'unitint':rnd.randint(1,25,size=n_size),\n                            'floatfull':rnd.random_sample(size=n_size),\n                            'floatsmall':np.round(rnd.random_sample(size=n_size)+rnd.randint(1,25,size=n_size),2),\n                            'categoryobj':rnd.choice(['a','b','c','d'],size=n_size),\n                            'stringobj':rnd.choice([\"{:c}\".format(k) for k in range(97, 123)],size=n_size)})\ndummy_data.head()\n\n\n\n\n\n  \n    \n      \n      numericfull\n      unitint\n      floatfull\n      floatsmall\n      categoryobj\n      stringobj\n    \n  \n  \n    \n      0\n      304\n      18\n      0.908959\n      8.56\n      a\n      c\n    \n    \n      1\n      212\n      24\n      0.348582\n      14.35\n      a\n      g\n    \n    \n      2\n      295\n      15\n      0.392977\n      21.98\n      a\n      y\n    \n    \n      3\n      54\n      20\n      0.720856\n      5.33\n      a\n      q\n    \n    \n      4\n      205\n      21\n      0.897588\n      23.03\n      c\n      k\n    \n  \n\n\n\n\nCreate a Dataset\n\ndataset = Dataset(df=dummy_data)\nprint(dataset)\nprint('Pandas Data Frame        : ',np.round(dummy_data.memory_usage(deep=True).sum()*1e-6,2),'MB')\nprint('Dataset Structured Array : ',np.round(dataset.data.nbytes*1e-6/ 1024 * 1024,2),'MB')\ndataset.data[:5]\n\nDataset(df=Shape((1000, 6), reduce_datatype=True, encode_category=None, add_intercept=False, na_treatment=allow, copy=False, digits=None, n_category=None, split_ratio=None)\nPandas Data Frame        :  0.15 MB\nDataset Structured Array :  0.03 MB\n\n\narray([(304, 18, 0.9089594 ,  8.56, 'a', 'c'),\n       (212, 24, 0.34858167, 14.35, 'a', 'g'),\n       (295, 15, 0.39297667, 21.98, 'a', 'y'),\n       ( 54, 20, 0.7208556 ,  5.33, 'a', 'q'),\n       (205, 21, 0.89758754, 23.03, 'c', 'k')],\n      dtype=[('numericfull', '<u2'), ('unitint', 'u1'), ('floatfull', '<f4'), ('floatsmall', '<f4'), ('categoryobj', 'O'), ('stringobj', 'O')])"
  }
]